---
title: "Project 2"
author: "Daniel Fredin, Junhan Li, & Eric Chen"
output: pdf_document
---

```{r include=FALSE, echo=FALSE}
# Libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(splitstackshape)
library(readr)
library(car)
library(lmtest)
library(rcompanion)
library(olsrr)
library(kableExtra)
library(caret)

library(lpSolve)
library(quadprog)
```


# Introduction 

By utilizing the glass identification dataset graciously provided by the USA Forensic Science Service, we have successfully derived insights and constructed a regression equation to forecast the occurrence of silicon (Si). This prediction is based on the observed oxide content found in the various types of glass examined in the study.

# Problem 1

## Part(a)

```{r include=FALSE, echo=FALSE}
glass <- read.csv("glass.csv")
```

```{r}
# Correlation for all numerical variables
cor(glass[,c("Si", "RI", "Na", "Mg", "Al", "K", "Ca", "Ba", "Fe")])
```

```{r warning=FALSE, message=FALSE}
# Select the highest correlated variables
glass_new <- glass %>%
  select(Si, RI, type)

# Rename for facet wrap labels
glass_names <- as_labeller(
  c('Con' = "Containers",
    'Head' = "Headlamps",
    'Tabl' = "Tableware",
    'Veh' = "Vehicle Windows (float glass)",
    'WinF' = "Building Windows (float glass)",
    'WinNF' = "Building Windows (non-float glass)")
)

# Scatter plot of Si vs RI for each glass type
ggplot(data= glass_new, aes(x=RI, y= Si, color = type)) +
  geom_point() +
  geom_smooth(method = lm, se = T) +
  facet_wrap(~type, labeller = glass_names) +
  labs(title = "Comparision of Silicon with it's refractive index in different types of glass",
       x = "Refractive Index", 
       y = "Silicon",
       color = "Glass Types") +
  theme_bw() +
  theme(legend.position = "none") +
  guides(color = guide_legend(nrow = 1))
```

To visualize the relationship between two numerical variables and illustrate the variation across different types of glass, we conducted a correlation analysis. Our aim was to identify the pair of variables with the highest correlation coefficient. In accordance with the given problem, we selected silicon (Si) as our dependent variable. Subsequently, we chose the refractive index (RI) as the independent variable due to its strong correlation with Si, indicated by a coefficient of -0.54. This implies a moderately negative correlation between Si and RI. As a result, we can infer that as the silicon content decreases, the refractive index of the glass is expected to increase.

Based on our visualization, it is evident that there exists a moderately negative correlation between Si and RI across all glass types, except for container glass, which surprisingly exhibits a moderately positive correlation. This peculiar pattern may be attributed to the elevated presence of water-insoluble oxides in container glass, contributing to enhanced chemical durability against water, a crucial requirement for storing beverages and food. Another noteworthy observation is that the refractive index tends to cluster around 0 for all glass types. This indicates that light passing through the glass travels at a velocity equal to that in a vacuum, exhibiting no bending or refraction. Such consistency around the refractive index of 0 appears to be a desirable characteristic across all glass types. While the majority of glass types exhibit a RI range between -5 and 5, it is worth noting that building windows display the widest RI range, with float glass spanning from -5 to 10 and non-float glass ranging from -5 to 15. On the other hand, vehicle glass demonstrates the smallest RI range, spreading from -2 to 4. In terms of Si concentration, tableware stands out with the highest Si content compared to other glass types, whereas building windows (non-float glass) generally possess the lowest Si concentration. Additionally, tableware showcases the most significant decline in Si per unit decrease in RI, indicating a steep relationship between these variables.

## Part (b) 

```{r}
# We will first check for the normality of dependent variable
shapiro.test(glass$Si)
boxplot(glass$Si, main = "Normality check for Silicon")
```

```{r} 
set.seed(123)

# Regular linear regression with all variables
glass_model1 <- lm(Si ~., data = glass)
predictions <- glass_model1 %>% predict(glass)
model1_results <- data.frame( R2 = R2(predictions, glass$Si),
            RMSE = RMSE(predictions, glass$Si),
            MAE = MAE(predictions, glass$Si))

# Regular linear regression with 4 variables from our visualization
glass_model2 <- lm(Si  ~ RI + factor(type) + Na + Ca , data = glass)
predictions <- glass_model2 %>% predict(glass)
model2_results <- data.frame( R2 = R2(predictions, glass$Si),
             RMSE = RMSE(predictions, glass$Si),
             MAE = MAE(predictions, glass$Si))

# Training and testing method
training <- glass$Si %>%
    createDataPartition(p = .75, list = FALSE)
train.data  <- glass[training, ]
test.data <- glass[-training, ]

glass_model3 <- lm(Si ~ Na + Mg + Al + K + Ca + Ba + Fe, data = train.data)
predictions <- glass_model3 %>% predict(test.data)
model3_results <- data.frame( R2 = R2(predictions, test.data$Si),
            RMSE = RMSE(predictions, test.data$Si),
            MAE = MAE(predictions, test.data$Si))
```


```{r, results = 'asis', echo=FALSE}
model_results <- rbind(model1_results, model2_results, model3_results)
row.names(model_results) <- c("Model 1", "Model 2", "Model 3")

model_kable <- kable(model_results, 
                    caption = "Summary of the accuracy and error exhibited by our three models.",
                    format = "latex",
                    align = "c",
                    booktabs = TRUE,
                    row.names = TRUE) %>%
  kable_styling(full_width = FALSE, latex_options = "HOLD_position")
print(model_kable)
```







TALK ABOUT OUR DATA NOT BEING NORMAL AND WE COULDN'T TRANSFORM IT TO A NORMAL DISTRIBUTION.


Argue your choice
- Perform optimization in R, compute the regression coefficients

The lower the value for AIC, the better the fit of the model. The absolute value of the AIC value is not important. It can be positive or negative.

Preconlcusion: Model 3 is a lot better. 
Based on the RMSE values we generated for the three models above, the model 3
where we used 75% training data model is our best model



```{r}
# Optimization of our best model
min.RSS <- function(data, par) {
              with(data, sum((par[1] + par[2] * Na + par[3] * Mg + par[4] * Al 
                              + par[5] * K + par[6] * Ca 
                              + par[7] * Ba + par[8] * Fe - Si)^2))
}

result <- optim(par = c(98, -1, -1, -1, -1, -1, -1, 0.5), 
                fn = min.RSS, 
                data = train.data)
```

```{r, results = 'asis', echo=FALSE}
coeff_results <- as.data.frame(rbind(glass_model3$coefficients, result$par))
row.names(coeff_results) <- c("Model 3", "Optimized Model 3")

model_kable <- kable(coeff_results, 
                    caption = "Summary of the coeffcients between our best model and our optimized model.",
                    format = "latex",
                    align = "c",
                    booktabs = TRUE,
                    row.names = TRUE) %>%
  kable_styling(full_width = FALSE, latex_options = "HOLD_position", "scale_down")
print(model_kable)
```





```{r}
# Fit the final model with the optimized coefficients
final_model <- lm(Si ~ Na + Mg + Al + K + Ca + Ba + Fe, data = train.data)

# Extract the optimized coefficients
optimized_coefficients <- result$par

names(optimized_coefficients) <- c("(Intercept)" ,"Na","Mg","Al","K","Ca","Ba","Fe")
# Update the coefficients of the final model with the optimized coefficients
final_model$coefficients <- optimized_coefficients

# Test final model
predictions <- final_model %>% predict(test.data)
final_model_results <- data.frame( R2 = R2(predictions, test.data$Si),
            RMSE = RMSE(predictions, test.data$Si),
            MAE = MAE(predictions, test.data$Si))
```


```{r, results = 'asis', echo=FALSE}
optimal_model_results <- rbind(model_results, final_model_results)
row.names(optimal_model_results) <- c("Model 1", "Model 2", "Model 3", "Optimized Model 3")

model_kable <- kable(optimal_model_results, 
                    caption = "Summary of the accuracy and error exhibited by all our models.",
                    format = "latex",
                    align = "c",
                    booktabs = TRUE,
                    row.names = TRUE) %>%
  kable_styling(full_width = FALSE, latex_options = "HOLD_position")
print(model_kable)
```




## Part (c) 

* (i) Coefficient of determination

```{r}
R2 <- final_model_results[1]
R2
```

The coefficient of determination, also known as R-squared, is a metric used in regression analysis to evaluate how well a model fits the data. It indicates the proportion of the dependent variable's variability that can be explained by the independent variables. R-squared ranges from 0 to 1, where 0 signifies that the independent variables have no influence on the variation, and 1 means they explain all of it. Our optimized best model had an impressive R-squared value of 0.9935,indicating that 99.35% of the dependent variable's variance is captured by the independent variables.

* (ii) Least-squares estimates for the regression line

```{r}
summary(final_model)
```

Regression equation:

$$
\begin{aligned}
\Large Si &= \Large  99.38 - (0.98 \cdot Na) - (0.99 \cdot Mg) - (1.00 \cdot Al) \\ &- \Large (1.00 \cdot K) - (0.98 \cdot Ca) - (0.96 \cdot Ba) - (0.38 \cdot Fe)
\end{aligned}
$$

* (iii) Slope and intercept interpretation

The regression coefficients correspond to the weight percent of each respective oxide. Thus, the intercept indicates that in the absence of any oxides, the glass will primarily consist of 99.38% silicon. The negative slopes indicate that an increase in the concentration of a specific oxide leads to a decrease in the silicon oxide content. Most of the oxide coefficients are approximately 1, except for iron oxide (Fe). For example, a one unit increase in Na oxide results in a 0.98 decrease in Si content, assuming all other factors remain constant. This relationship is sensible, as the addition of one unit of another oxide typically leads to a corresponding decrease in Si content. However, a one unit increase in Fe oxide content only causes a 0.38 decrease in Si content, while holding all other factors constant. This discrepancy may be attributed to the fact that Fe is an impurity in the glass-making process and is not intentionally added to achieve desired effects, such as Na or Ca.

At a 10% confidence level, all of the variables in our optimized best model exhibit significant predictability for Si content, as indicated by their p-values being less than 0.10. The variables found to be significant predictors are Na, Mg, Al, K, Ca, Ba, and Fe.


* (iv) Residual analysis

```{r}
# Check for normality of using shapiro test on residuals
# (This predicts residuals on training data)
real_resid <- residuals(final_model)
shapiro.test(real_resid) 

# (This predicts residuals on testing data)
resids <- test.data$Si - predictions 
shapiro.test(resids) 

# Check for Linearity  using rainbow test
raintest(final_model)

# Check for multicollinearity 
cat("Check for multicollinearity\n\n")
vif(final_model)
 
# Check for autocorrelation 
dwtest(final_model)

# Check for Heteroskedasticity
ols_test_breusch_pagan(final_model) 

# Check for outliers
ols_plot_resid_stud(final_model) 

par(mfrow = c(2,2))
plot(final_model)
```

The Shapiro test performed on the residuals of our optimized model and training data indicates that they deviate from normality, as the p-value is less than 0.05. Conversely, when applying the Shapiro test to the residuals of our optimized model and testing data, we find that the residuals for the testing data follow a normal distribution, as the p-value (0.7865) is greater than 0.05. Utilizing the rainbow test on our optimized model, we find no evidence of violating the linearity assumption. The null hypothesis of a linear fit is not rejected, as the p-value (0.9892) is greater than 0.05. The test for multicollinearity results in GVIFs lower than 5 for all variables, indicating the absence of multicollinearity. According to the Durban-Watson test for autocorrelation, we can confidently assume that the residuals are not correlated with one another, given the p-value exceeding 0.05. The Breusch Pagan test for heteroskedasticity reveals a violation of the equal variance assumption in our optimized model, as the p-value is less than 0.05. Moreover, upon observing the Studentized Residuals plot, it becomes evident that there is an outlier present. This outlier is observed in our training data but not in our testing data.


## Part (d)
```{r}

glass_mutate <- glass %>%
  filter(type == "WinF" | type == "WinNF")

# Check 1 Independent of one another
boxplot(Al ~ type, 
        data = glass_mutate, 
        main = "Comparison of AL and types: WinF and WinNF")

# Check 2: Normality
shapiro.test(glass_mutate$Al)


# Check 3: Levene's test, The two groups have equal variance
var.test(Al ~ type, 
         data = glass_mutate,
         conf.level = 0.9)


# Perform a non-parametric test: Since the distribution of Al is not normal, use a 
# non-parametric test, such as the Wilcoxon-Mann-Whitney test, to compare the 
# medians of the two groups
wilcox_result <- wilcox.test(Al ~ type, 
                             data = glass_mutate, 
                             var.equal = TRUE,
                             conf.level = 0.9)
wilcox_result
p_value <- wilcox_result$p.value

```

```{r include = TRUE, echo=FALSE}
if (p_value < 0.1) {
  cat("\nThe distributions of the two groups are significantly different at the 10% significance level.")
} else {
  cat("\nThe distributions of the two groups are not significantly different at the 10% significance level.")
}
```

The Shaprio test reveals a deviation from normal distribution in Al, as evidenced by a p-value below 0.05. Consequently, a t-test comparing the means of the two groups cannot be conducted due to the non-normality. However, the two groups are independent and exhibit variances that are not significantly dissimilar, as indicated by an F test p-value exceeding 0.05. Thus, it is appropriate to employ a non-parametric test like the Wilcoxon-Mann-Whitney test to compare the medians of the two groups. Employing a 10% level of significance, the distributions of the two groups, WinF and WinNF, are markedly distinct since the p-value for the Wilcoxon test is significantly below 0.05.


## Part (e):

```{r}
set.seed(123)
# Need 214 values
N <- 214

Na <- rnorm(n=N, mean = mean(glass$Na), sd(glass$Na))
Mg <- rnorm(n=N, mean = mean(glass$Mg), sd(glass$Mg))
Al <- rnorm(n=N, mean = mean(glass$Al), sd(glass$Al))
K <- rnorm(n=N, mean = mean(glass$K), sd(glass$K))
Ca <- rnorm(n=N, mean = mean(glass$Ca), sd(glass$Ca))
Ba <- rnorm(n=N, mean = mean(glass$Ba), sd(glass$Ba))
Fe <- rnorm(n=N, mean = mean(glass$Fe), sd(glass$Fe))


e <- rnorm(n=N, 0, 1)

# Saves coefficients from our model3 as variables
coef <- summary(final_model)$coefficients

Si <- e + coef[1] + coef[2]*Na + coef[3]*Mg + coef[4]*Al + coef[5]*K + 
  coef[6]*Ca + coef[7]*Ba + coef[8]*Fe

simulated_glass <- cbind(Na, Mg, Al, K, Ca, Ba, Fe, Si)
simulated_glass <- as.data.frame(simulated_glass)

summary(Si)
```

Using the mean and standard deviation of each observed variable, we generated simulated data for each variable. Given that our observed data is approximately normally distributed, we opted to employ the normal distribution method for generating the simulated data for all the independent variables.

Upon examination, we observed that the simulated Si values range from 65.79 to 80.43. The median value of our simulated Si data is 72.43, with a mean of 72.56. In comparison, the observed data has a median of 72.79 and a mean of 75.65. The interquartile range of the simulated Si values falls within 71.00 to 74.44.


```{r}
set.seed(123)
# Simulated model using the technique 
training <- simulated_glass$Si %>%
    createDataPartition(p = .75, list = FALSE)
train.data  <- simulated_glass[training, ]
test.data <- simulated_glass[-training, ]

sim_model<- lm(Si ~ Na + Mg + Al + K + Ca + Ba + Fe, data = train.data)
predictions <- glass_model3 %>% predict(test.data)
sim_model_results <- data.frame( R2 = R2(predictions, test.data$Si),
            RMSE = RMSE(predictions, test.data$Si),
            MAE = MAE(predictions, test.data$Si))

sim_model_results
summary(sim_model)
```
Simulated Model Regression equation:

$$
\begin{aligned}
\Large Si &= \Large  99.01 - (0.96 \cdot Na) - (0.99\cdot Mg) - (0.99 \cdot Al) \\ &- \Large (1.13 \cdot K) - (0.97 \cdot Ca) - (0.77 \cdot Ba) + (1.29 \cdot Fe)
\end{aligned}
$$

This regression equation suggests that when none of the critical elements are present in the glass, 99.01% of the material will be Si. The negative slopes in the equation means that an increase of the presence of any other element by one percent will decrease the Si content of the glass by roughly one percent, which makes sense. 

It is clearly to see that our simulated regression has completely different coefficients for iron where for every one percent of increase in iron, the percentage of materials that are silicon in the glass will increases by 1.3%. (Certain chemical properties?)

```{r}
# Check for normality using shapiro test on residuals
sim_resid <- residuals(sim_model)
shapiro.test(sim_resid) 

# Check for Linearity using rainbow test
raintest(sim_model)

# Check for multicollinearity 
cat("Check for multicollinearity\n\n")
vif(sim_model)
 
# Check for autocorrelation 
dwtest(sim_model)

# Check for Heteroskedasticity
ols_test_breusch_pagan(sim_model) 

# Check for outliers
ols_plot_resid_stud(sim_model) 

par(mfrow = c(2,2))
plot(sim_model)
```

The Shapiro test conducted on the residuals of our simulated model and simulated data indicates that they follow a normal distribution, as the p-value is greater than 0.05. By performing the rainbow test on our simulated model, we find no evidence of violating the assumption of linearity. The null hypothesis of a linear fit is not rejected, as the p-value is greater than 0.05. The test for multicollinearity yields GVIFs less than 5 for all variables, suggesting the absence of multicollinearity. According to the Durban-Watson test for autocorrelation, we can safely assume that the residuals are not correlated with each other, given the p-value greater than 0.05. The Breusch Pagan test for heteroskedasticity indicates that the equal variance assumption holds in our simulated model. Upon examination of the Studentized Residuals plot, there is no clear evidence of outliers present in the residuals of our simulated model.

Upon comparing the residuals of our optimized model to those of the simulated model, we observe that all assumptions remain consistent, except for the fact that our simulated data follows a normal distribution. This outcome aligns with expectations, as the simulated data was intentionally generated to adhere to a normal distribution.

# Problem 3

## Part (a)
```{r include=FALSE, echo=FALSE}
Handout1 <- read.csv("Handout 1.csv")
```

We opted to select independent variables that exclusively comprised discrete or continuous numerical values, excluding factors such as the teacher's sex, type of school, or teaching level. Our decision was based on the belief that this variable selection, combined with 10-fold cross-validation, would yield the highest level of accuracy in our model.

### 10-fold Cross-Validation

```{r}
# Convert COMMIT to binary < median = 0, otherwise = 1.

new_Handout1 <- Handout1 %>%
  mutate(COMMIT = case_when(
    (COMMIT < median(COMMIT)) ~ 0,
    TRUE ~ 1))

# Select only the continuous numerical variables
new_Handout1 <- new_Handout1 %>%
  select(COMMIT, AGE, SALARY, CLASSSIZE, RESOURCES, AUTONOMY, CLIMATE, SUPPORT)


# Training and testing method
set.seed(123)
# Create training and testing data
index <- createDataPartition(new_Handout1$COMMIT, 
                             p = 0.8, 
                             list = FALSE,
                             times=1)


new_Handout1 <- as.data.frame(new_Handout1)

train  <- new_Handout1[index, ]
test <- new_Handout1[-index, ]

train$COMMIT[train$COMMIT==1] <- "yes"
train$COMMIT[train$COMMIT==0] <- "no"

test$COMMIT[test$COMMIT==1] <- "yes"
test$COMMIT[test$COMMIT==0] <- "no"


# Convert outcome variable to factor for each data frame
train$COMMIT <- as.factor(train$COMMIT)
test$COMMIT <- as.factor(test$COMMIT)

# 10-fold Cross-validation method
ctrlspecs <- trainControl(method="cv", 
                          number=10, 
                          savePredictions="all",
                          classProbs=TRUE)

set.seed(1234)
cvmodel <- train(COMMIT ~ .,  
                 data=train, 
                 method="glm", 
                 family = "binomial",  
                 trControl=ctrlspecs)

# Model summary for 10-fold Cross-validation method
summary(cvmodel)
# Model for 10-fold Cross-validation method
print(cvmodel)
# Important variables for 10-fold Cross-validation method
varImp(cvmodel)
```

### Model Accuracy

```{r}
# Predict outcome using model from training data based on testing data
predictions <- predict(cvmodel, newdata=test)

# Create confusion matrix to assess model fit/performance on test data
con_matx <- confusionMatrix(data=predictions, test$COMMIT)
con_matx
```

After examining the confusion matrix, it becomes apparent that our model attained an accuracy rate of 80% (95% CI: 0.61-0.92) when tested on the data. As the p-value exceeds 0.05, this suggests that our model exhibits a statistically significant level of accuracy.

## Part (b)

Our objective is to optimize the cost function in order to identify the most economical approach for fulfilling the Christmas order. This entails striving for the lowest cost per day to achieve maximum cost efficiency. By minimizing expenses at each factory, we can ensure a cost-effective process for meeting the demands of the Christmas order.


```{r}
factories <- c("Factory A", "Factory B", "Factory C")
toys <- c("Cars", "Animals", "Robots")

# Define the coefficients of the objective function
costs <- c(1000, 2100, 1500)

# Define the constraint matrix
constraint_matrix <- matrix(c(30, 20, 30,
                              40, 50, 10,
                              50, 40, 15), nrow = 3, byrow = TRUE)

# Define the right-hand side of the constraints
constraint_limits <- c(5000, 3000, 2500)

# Set the direction of optimization (minimization)
constraint_directions <- c(">=", ">=", ">=")
direction <- "min"

# Solve the linear programming problem
min_solution <- lp(direction = direction,
                   objective.in = costs,
                   const.mat = constraint_matrix,
                   const.dir = constraint_directions,
                   const.rhs = constraint_limits, 
                   compute.sens=TRUE)

# Check if a solution was found
if (min_solution$status == 0) {
  # Print the optimal solution
  cat("The optimal solution is:\n")
  cat("Factory A:",min_solution$solution[1], "days","\n")
  cat("Factory B:",min_solution$solution[2], "days","\n")
  cat("Factory C:",min_solution$solution[3], "days","\n\n")
  # Print the minimum cost
  cat("The value of the objective function at the optimal solution is:\n")
  cat("Minimum cost: $",min_solution$objval)
} else {
  # No feasible solution found
  print("No feasible solution found.")
}
```

The most efficient approach entails running Factory A for approximately 166.67 days, resulting in a minimal cost of $166,666.70, whereas Factory B and Factory C remain non-operational. By adopting this strategy, the company can achieve the most cost-effective outcome.

When considering the optimal solution, it is important to analyze the cost implications of running the factories for different durations. In this scenario, operating Factory for approximately 166.67 days leads to the minimum overall cost. By halting the operations of Factory B and Factory C, the company can avoid additional expenses associated with their functioning.


```{r include=TRUE, echo=FALSE}
# Create an empty data frame to store the results
result_df <- data.frame()
factories <- c("Factory A", "Factory B", "Factory C")
toys <- c("Cars", "Animals", "Robots")

# Iterate over the range of 1:3
for (i in 1:3) {
  
  # Store values for rows and columns in the data frame
  row_df <- data.frame(Factory = factories[i],
                       min_days = min_solution$solution[i],
                       min_cost = min_solution$solution[i]*costs[i])
  result_df <- rbind(result_df, row_df)

}

colnames(result_df) <- c("",
                         "Minimum operating days",
                         "Minimum costs")

# Print the resulting data frame
cat("The summary of the results:")
print(result_df)
```

## Part (c)

```{r}
# Weibull statistics
# lambda is scale while K is shape
compute_weibull_stats <- function(shape, scale) {
  
  # Compute the mean
  mean_value <- scale * gamma(1 + (1/shape))
  
  # Compute the median
  median_value <- scale * (log(2)^(1/shape))
  
  # Compute the mode
  if (shape > 1)
    mode_value <- scale * ((shape - 1) / shape)^(1/shape)
  else
    mode_value <- 0
  
  # Compute the variance
  variance_value <- scale^2 * (gamma(1 + (2/shape)) - (gamma(1 + (1/shape)))^2)
  
  # Return the computed statistics as a named list
  return(list(mean = mean_value, 
              median = median_value, 
              mode = mode_value, 
              variance = variance_value))
}

# Example usage
scale_param <- 6
shape_param <- 1

stats <- compute_weibull_stats(shape_param, scale_param)

# Accessing the computed statistics
mean_value <- stats$mean
median_value <- stats$median
mode_value <- stats$mode
variance_value <- stats$variance
```

When $\lambda =`r scale_param`$ and $k = `r shape_param`$ then the Weibull statistics are:  
$Mean = `r mean_value`\\$
$Median = `r median_value` \\$
$Mode = `r mode_value` \\$
$Variance = `r variance_value`$


### Maximum likelihood estimator (MLE) of the parameters from the Weibull distribution


Probability Density Function $(f(x;\lambda,k))$ for the Weibull distribution:


$$
\Large f(x;\lambda,k) = 
\begin{cases}
  \Large\frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}  e^{-\left(\frac{x}{\lambda}\right)^k}  , & x \ge 0\\
  \Large0, &x < 0
\end{cases}
$$


The likelihood function $(L_{\hat{x}}(\lambda,k))$:


$$
\begin{aligned}
 \Large L_{\hat{x}}(\lambda,k) &= \Large \prod_{i=1}^{n} \frac{k}{\lambda}\left(\frac{x_i}{\lambda}\right)^{k-1}  e^{-\left(\frac{x_i}{\lambda}\right)^k} \\
 &= \Large\left(\frac{k}{\lambda}\right)^n    \left(\frac{1}{\lambda^{k-1}}\right)^n    \left(\prod_{i=1}^{n}x_i^{k-1}\right)    \left(e^{-\sum\limits_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k}\right)  \\
 &=\Large \frac{k^n}{\lambda^{nk}}    e^{-\sum\limits_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k}    \prod_{i=1}^{n}x_i^{k-1}    
\end{aligned}
$$


The log-likelihood function $(\ln L_{\hat{x}}(\lambda,k))$:


$$
\Large \ln L_{\hat{x}}(\lambda,k) = \Large n\ln(k) - nk\ln(\lambda) - \sum\limits_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k + (k-1)\sum\limits_{i=1}^{n}\ln x_i
$$


Partial derivative of the log-likelihood function with respect to $\lambda$:


$$
\large \frac{\partial \ln L_{\hat{x}}(\lambda,k)}{\partial \lambda} = \Large -\frac{nk}{\lambda} + k\sum\limits_{i=1}^{n} \frac{x_i^k}{\lambda^{k+1}}
$$


Solving for the desired parameter of $\lambda$ by setting the partial derivative equal to zero:

$$
\begin{aligned}
\large \frac{\partial \ln L_{\hat{x}}(\lambda,k)}{\partial \lambda} &= \Large 0 \\
\Large -\frac{nk}{\lambda} + k\sum\limits_{i=1}^{n} \frac{x_i^k}{\lambda^{k+1}} &= \Large0 \\
\Large -\frac{nk}{\lambda} + \frac{k}{\lambda}\sum\limits_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k & = \Large0 \\
\Large - n +\sum\limits_{i=1}^{n}\frac{x_i^k}{\lambda^k} &= \Large 0 \\
\Large \frac{1}{\lambda^k} \sum\limits_{i=1}^{n}x_i^k &= \Large n \\
\Large \frac{1}{n} \sum\limits_{i=1}^{n}x_i^k &= \Large \lambda^k
\end{aligned}
$$

Therefore the estimator $\hat{\lambda}$ is:

$$
\Large \hat{\lambda} = \Large \left( \frac{1}{n} \sum\limits_{i=1}^{n}x_i^k \right)^\frac{1}{k}
$$






Plugging in $\hat{\lambda}$ into the log-likelihood function $(\ln L_{\hat{x}}(\lambda,k))$ and then differentiating with respect to $k$ in order to find the estimator $\hat{k}$:


$$
\begin{aligned}
\large \frac{\partial \ln L_{\hat{x}}(\lambda,k)}{\partial k} &= \Large \frac{\partial}{\partial k} \left[ n\ln k - nk\ln \lambda - \sum\limits_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k + (k-1)\sum\limits_{i=1}^{n}\ln x_i \right] \\
&= \Large \frac{\partial}{\partial k} \left[ n\ln k - nk\ln\left[ \left( \frac{1}{n} \sum\limits_{i=1}^{n}x_i^k \right)^\frac{1}{k}  \right] - \frac{\sum\limits_{i=1}^{n}x_i^k}{\left[ \left( \frac{1}{n} \sum\limits_{i=1}^{n}x_i^k \right)^\frac{1}{k} \right]^k} + (k-1)\sum\limits_{i=1}^{n}\ln x_i \right] \\
&= \Large \frac{\partial}{\partial k} \left[ n\ln k - \frac{nk}{k}\ln\left( \frac{1}{n} \sum\limits_{i=1}^{n}x_i^k \right) - \frac{\sum\limits_{i=1}^{n}x_i^k}{\left( \frac{1}{n} \sum\limits_{i=1}^{n}x_i^k \right)} + (k-1)\sum\limits_{i=1}^{n}\ln x_i \right] \\
&= \Large \frac{\partial}{\partial k} \left[ n\ln k - n\ln\left( \frac{1}{n} \sum\limits_{i=1}^{n}x_i^k \right) - n + (k-1)\sum\limits_{i=1}^{n}\ln x_i \right] \\
&= \Large \frac{n}{k} - \left( \frac{n\sum\limits_{i=1}^{n}x_i^k\ln{x_i}}{\sum\limits_{i=1}^{n}x_i^k} \right) + \sum\limits_{i=1}^{n}\ln x_i \\
&= \Large \frac{1}{k} - \left( \frac{\sum\limits_{i=1}^{n}x_i^k\ln{x_i}}{\sum\limits_{i=1}^{n}x_i^k} \right) + \frac{1}{n}\sum\limits_{i=1}^{n}\ln x_i
\end{aligned}
$$


Solving for the desired parameter of $k$ by setting the partial derivative equal to zero:

$$
\begin{aligned}
\large \frac{\partial \ln L_{\hat{x}}(\lambda,k)}{\partial k} &= \Large 0 \\
\Large \frac{1}{k} - \left( \frac{\sum\limits_{i=1}^{n}x_i^k\ln{x_i}}{\sum\limits_{i=1}^{n}x_i^k} \right) + \frac{1}{n}\sum\limits_{i=1}^{n}\ln x_i &= \Large 0 \\
\Large  \left( \frac{\sum\limits_{i=1}^{n}x_i^k\ln{x_i}}{\sum\limits_{i=1}^{n}x_i^k} \right) - \frac{1}{n}\sum\limits_{i=1}^{n}\ln x_i&= \Large \frac{1}{k}
\end{aligned}
$$



Therefore the estimator $\hat{k}$ is:

$$
\Large \hat{k} = \left[ \Large \frac{\sum\limits_{i=1}^{n}x_i^k\ln{x_i}}{\sum\limits_{i=1}^{n}x_i^k}  - \frac{1}{n}\sum\limits_{i=1}^{n}\ln x_i \right]^{-1}
$$

The definition of $\hat{k}$ provided here is implicit, as determining the value of $k$ typically requires numerical methods for solution.